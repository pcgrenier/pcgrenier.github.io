
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Category: processors - NiFi.rocks</title>
  <meta name="author" content="">

<meta name="description" content="Category: processors">
<meta name="keywords" content="Apache Nifi, Nifi, nifi, nifi rocks">
  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.nifi.rocks/categories/processors/atom.xml">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="NiFi.rocks" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-57621921-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner">
	<div class="header-title"><a href="/">NiFi.rocks</a></div>


	<br><div class="header-subtitle">Your home for everything Apache NiFi</div>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.nifi.rocks" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: processors | NiFi.rocks]]></title>
  <link href="http://www.nifi.rocks/categories/processors/atom.xml" rel="self"/>
  <link href="http://www.nifi.rocks/"/>
  <updated>2015-04-09T02:51:22+00:00</updated>
  <id>http://www.nifi.rocks/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Developing a Custom Apache Nifi Processor-Unit Tests (Part I)]]></title>
    <link href="http://www.nifi.rocks/developing-a-custom-apache-nifi-processor-unit-tests-partI/"/>
    <updated>2015-04-04T16:54:52+00:00</updated>
    <id>http://www.nifi.rocks/developing-a-custom-apache-nifi-processor-unit-tests-partI</id>
    <content type="html"><![CDATA[<p>The Apache Nifi framework has built in unit testing with Junit using test runners.  They have a few examples in their code base, but learning first hand really helps.  In this post we&rsquo;ll go over adding unit tests to the <a href="{{%20site.url%20}}/developing-a-custom-apache-nifi-processor-json/">JSON Processor</a> that we developed previously.</p>

<p>To start, we&rsquo;ll checkout the JSON Processor code from <a href="https://github.com/pcgrenier/nifi-examples">Github</a> and then open it up in your favorite text editor.  There is already a test package/folder in the project that contains a unit test, <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/test/java/rocks/nifi/examples/processors/JsonProcessorTest.java">rocks.nifi.examples.processors/JsonProcessorTest.java</a>.</p>

<p>When unit testing in Apache Nifi, there are a few items on top of the normal JUnit annotations that are required.  While you can unit test with just JUnit, using the built in method in Apache Nifi makes it much easier.  In a future post we&rsquo;ll show you how to unit test using Mockito and JUnit to test helper methods where actually invoking a full processor seems excessive, or if you just don&rsquo;t want to use Nifi&rsquo;s test runner.</p>

<!-- more -->


<p>The first thing to do to unit test Apache Nifi is grabbing the necessary dependencies from maven.</p>

<p>{% codeblock lang:xml pom.xml <a href="https://github.com/pcgrenier/nifi-examples/blob/master/pom.xml#L42">https://github.com/pcgrenier/nifi-examples/blob/master/pom.xml#L42</a> %}
        <dependency>
            <groupId>org.apache.nifi</groupId>
            <artifactId>nifi-mock</artifactId>
            <version>${nifi.version}</version>
            <scope>test</scope>
        </dependency></p>

<p>{% endcodeblock %}</p>

<p>After including the nifi-mock dependency, there will be a few includes from the org.apache.nifi.utils package that will be necessary to import; mainly TestRunner, TestRunners and MockFlowFile.</p>

<p>Since we are using JUnit, the usual tags apply for defining a test function inside the class and we&rsquo;ll use the @Test for this one, although the other annotations can be used.  After adding the JUnit tag, there are a few requirements that Nifi puts on you in order to utilize the test runners they have provided.  The first is to create a test runner to use and then to set a flow file or flow file content inorder to run the processor.  In this example, we are using a ByteArrayInputStream as the flow file content, although you could use a JSON file in a resource folder just as well.</p>

<p>Once a test runner is created, you can set flow file properties on it using <code>runner.setProperties(PropertyDescriptor)</code> method and can enqueue a file using <code>runner.enqueue(content)</code>.  Then you can run the test runner and make assertions.</p>

<p>Nifi makes it easy to test assertions with some built in assertions for flowfiles.  You can test the flowfile was transfered to the appropriate relationship and get the flowfile to test for expected attributes and content.</p>

<p>Below is how we test the JSON Processor, with a typical test setup for Apache Nifi.</p>

<p>{% codeblock lang:java JSON Processor Unit Test <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/test/java/rocks/nifi/examples/processors/JsonProcessorTest.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/test/java/rocks/nifi/examples/processors/JsonProcessorTest.java</a> JsonProcessorTest.java %}
@org.junit.Test
    public void testOnTrigger() throws IOException {
        // Content to be mock a json file
        InputStream content = new ByteArrayInputStream(&ldquo;{&#34;hello\&rdquo;:\&ldquo;nifi rocks\&rdquo;}&ldquo;.getBytes());</p>

<pre><code>    // Generate a test runner to mock a processor in a flow
    TestRunner runner = TestRunners.newTestRunner(new JsonProcessor());

    // Add properites
    runner.setProperty(JsonProcessor.JSON_PATH, "$.hello");

    // Add the content to the runner
    runner.enqueue(content);

    // Run the enqueued content, it also takes an int = number of contents queued
    runner.run(1);

    // All results were processed with out failure
    runner.assertQueueEmpty();

    // If you need to read or do aditional tests on results you can access the content
    List&lt;MockFlowFile&gt; results = runner.getFlowFilesForRelationship(JsonProcessor.SUCCESS);
    assertTrue("1 match", results.size() == 1);
    MockFlowFile result = results.get(0);
    String resultValue = new String(runner.getContentAsByteArray(result));
    System.out.println("Match: " + IOUtils.toString(runner.getContentAsByteArray(result)));

    // Test attributes and content
    result.assertAttributeEquals(JsonProcessor.MATCH_ATTR, "nifi rocks");
    result.assertContentEquals("nifi rocks");

}
</code></pre>

<p>{% endcodeblock %}</p>

<p>Watch for our next post about unit testing Apache Nifi with Mockito and JUnit without using nifi&rsquo;s testrunner class.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developing A Custom Apache Nifi Processor (JSON)]]></title>
    <link href="http://www.nifi.rocks/developing-a-custom-apache-nifi-processor-json/"/>
    <updated>2015-02-07T02:14:33+00:00</updated>
    <id>http://www.nifi.rocks/developing-a-custom-apache-nifi-processor-json</id>
    <content type="html"><![CDATA[<p>The list of available Apache Nifi processors is extensive, as documented in <a href="{{%20site.url%20}}/apache-nifi-processors/">this post</a>. There is still a need to develop your own; to pull data from a database, to process an uncommon file format, or many other unique situations. So to get you started, we will work through a basic processor that takes a json file as input and a json path as a parameter to place into the contents and an attribute. The full source is hosted on <a href="https://github.com/pcgrenier/nifi-examples">Github</a>.</p>

<!-- more -->


<h2>Setup</h2>

<p>Start by creating a simple maven project in your favorite IDE. Then edit the pom.xml.</p>

<p>{% gist f99d27d08c3903f9d50c pom.xml %}</p>

<p>This pom.xml includes a single plug-in for building a nifi nar, which is similar to a war for nifi, that bundles everything up in a way nifi can unpack. The nifi-api is the only other &ldquo;required&rdquo; dependency. The other nifi dependencies are really use full as you will see.</p>

<p>The next important piece is telling nifi which classes to load and register. This is done in a single file located at /src/main/resources/META-INF/services/org.apache.nifi.processor.Processor</p>

<p>{% gist f98e563e787c1b73c425 org.apache.nifi.processor.Processor %}</p>

<h2>The JSON Processor</h2>

<p>Now that everything is defined and findable by Apache Nifi, lets build a processor. Define a simple java class as defined in the setup process (rocks.nifi.examples.processors.JsonProcessor).</p>

<p>Tags are useful for finding your processor in the list of processors in the GUI. So in this case in the search box you could just type &lsquo;json&rsquo; and your processor will be found. The capability description is also displayed in the processor selection box. Nifi.rocks will make future posts on documenting your custom processors. Finally most processors will just extend the AbstractProcessor, for more complicated tasks it may be required to go a level deeper for the AbstractSessionFactoryProcessor.</p>

<p>{% codeblock lang:java Apache Nifi Processor Header  <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}
@SideEffectFree
@Tags({&ldquo;JSON&rdquo;, &ldquo;NIFI ROCKS&rdquo;})
@CapabilityDescription(&ldquo;Fetch value from json path.&rdquo;)
public class JsonProcessor extends AbstractProcessor {
{% endcodeblock %}</p>

<p>Not really interesting stuff here. Properties will hold all a list of all the available properties tha are exposed to the user. Relationships will hold the relationships the processor will use to direct the flow files. For more details on relationships, properties, and components of an Apache Nifi flow please read the <a href="https://nifi.incubator.apache.org/docs/nifi-docs/developer-guide.html">offical developer guide</a>. There is plenty of room to expand on custom validators, but there is a large selection of validators in nifi-processor-utils package.</p>

<p>{% codeblock lang:java Variable Declaration <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}</p>

<p>private List<PropertyDescriptor> properties;
private Set<Relationship> relationships;</p>

<p>public static final String MATCH_ATTR = &ldquo;match&rdquo;;</p>

<p>public static final PropertyDescriptor JSON_PATH = new PropertyDescriptor.Builder()
        .name(&ldquo;Json Path&rdquo;)
        .required(true)
        .addValidator(StandardValidators.NON_EMPTY_VALIDATOR)
        .build();</p>

<p>public static final Relationship SUCCESS = new Relationship.Builder()
        .name(&ldquo;SUCCESS&rdquo;)
        .description(&ldquo;Succes relationship&rdquo;)
        .build();
{% endcodeblock %}</p>

<p>The init function is called at the start of Apache Nifi. Remember that this is a highly multi-threaded environment and be careful what you do in this space. This is why both the list of properties and the set of relationships are set with unmodifiable collections. I put the getters for the properties and relationships here as well.</p>

<p>{% codeblock lang:java Apache Nifi Init <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}
@Override
public void init(final ProcessorInitializationContext context){
    List<PropertyDescriptor> properties = new ArrayList&lt;>();
    properties.add(JSON_PATH);
    this.properties = Collections.unmodifiableList(properties);</p>

<pre><code>Set&lt;Relationship&gt; relationships = new HashSet&lt;&gt;();
relationships.add(SUCCESS);
this.relationships = Collections.unmodifiableSet(relationships);
</code></pre>

<p>}</p>

<p>@Override
public Set<Relationship> getRelationships(){
    return relationships;
}</p>

<p>@Override
public List<PropertyDescriptor> getSupportedPropertyDescriptors(){
    return properties;
}
{% endcodeblock %}</p>

<p>The onTrigger method is called when ever a flow file is passed to the processor. For more details on the context and session variables please again refer to the <a href="https://nifi.incubator.apache.org/docs/nifi-docs/developer-guide.html#flowfile">official developer guide</a>.</p>

<p>{% codeblock lang:java Apache Nifi OnTrigger <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}</p>

<p>@Override
public void onTrigger(ProcessContext context, ProcessSession session) throws ProcessException {
    final ProcessorLog log = this.getLogger();
    final AtomicReference<String> value = new AtomicReference&lt;>();</p>

<pre><code>FlowFile flowfile = session.get();

session.read(flowfile, new InputStreamCallback() {
    @Override
    public void process(InputStream in) throws IOException {
        try{
            String json = IOUtils.toString(in);
            String result = JsonPath.read(json, "$.hello");
            value.set(result);
        }catch(Exception ex){
            ex.printStackTrace();
            log.error("Failed to read json string.");
        }
    }
});

// Write the results to an attribute
String results = value.get();
if(results != null &amp;&amp; !results.isEmpty()){
    flowfile = session.putAttribute(flowfile, "match", results);
}

// To write the results back out ot flow file
flowfile = session.write(flowfile, new OutputStreamCallback() {

    @Override
    public void process(OutputStream out) throws IOException {
        out.write(value.get().getBytes());
    }
});

session.transfer(flowfile, SUCCESS);
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>In general you pull the flow file out of session. Read and write to the flow files and add attributes where needed. To work on flow files nifi provides 3 callback interfaces.</p>

<ul>
<li><p>InputStreamCallback: For reading the contents of the flow file through a input stream.</p>

<p>Using Apache Commons to read the input stream out to a string. Use JsonPath to attempt to read the json and set a value to the pass on. It would normally be best practice in the case of a exception to pass the original flow file to a Error relation point in the case of an exception.</p></li>
</ul>


<p>{% codeblock lang:java Apache Nifi InputStreamCallback <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}
session.read(flowfile, new InputStreamCallback() {
    @Override
    public void process(InputStream in) throws IOException {
        try{
            String json = IOUtils.toString(in);
            String result = JsonPath.read(json, &ldquo;$.hello&rdquo;);
            value.set(result);
        }catch(Exception ex){
            ex.printStackTrace();
            log.error(&ldquo;Failed to read json string.&rdquo;);
        }
    }
});<br/>
{% endcodeblock %}</p>

<ul>
<li><p>OutputStreamCallback: For writing to a flowfile, this will over write not concatenate.</p>

<p>We simply write out the value we recieved in the InputStreamCallback</p></li>
</ul>


<p>{% codeblock lang:java Apache Nifi OutputStreamCallback <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}
flowfile = session.write(flowfile, new OutputStreamCallback() {
    @Override
    public void process(OutputStream out) throws IOException {
        out.write(value.get().getBytes());
    }
});
{% endcodeblock %}</p>

<ul>
<li>StreamCallback: This is for both reading and writing to the same flow file. With both the outputstreamcallback and streamcall back remember to assign it back to a flow file. This processor is not in use in the code and could have been. The choice was deliberate to show a way of moving data out of callbacks and back in.</li>
</ul>


<p>{% codeblock lang:java Apache Nifi StreamCallback %}
flowfile = session.write(flowfile, new StreamCallback() {
    @Override
    public void process(InputStream in, OutputStream out) throws IOException {
        String json = IOUtils.toString(in);
        String result = JsonPath.read(json, &ldquo;$.hello&rdquo;);
        out.write(result.getBytes());
    }
});
{% endcodeblock %}</p>

<p>Flow files can also contain meta data in attributes to push between processors.</p>

<p>{% codeblock lang:java Setting low file attributes <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}
// Write the results to an attribute
String results = value.get();
if(results != null &amp;&amp; !results.isEmpty()){
    flowfile = session.putAttribute(flowfile, &ldquo;match&rdquo;, results);
}
{% endcodeblock %}</p>

<p>Finally every flow file that is generated needs to be deleted or transfered.</p>

<p>{% codeblock lang:java Session Transfer <a href="https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java">https://github.com/pcgrenier/nifi-examples/blob/master/src/main/java/rocks/nifi/examples/processors/JsonProcessor.java</a> JsonProcessor.java %}
session.transfer(flowfile, SUCCESS);
{% endcodeblock %}</p>

<p>At this point you should be able to build with a simple</p>

<p>{% codeblock lang:shell-session %}
mvn clean install
{% endcodeblock %}</p>

<h2>Deployment</h2>

<ol>
<li>Copy the target/examples-1.0-SNAPSHOT.nar to $NIFI_HOME/lib</li>
<li>$NIFI_HOME/bin/nifi.sh stop</li>
<li>$NIFI_HOME/bin/nifi.sh start</li>
</ol>


<p>After Nifi finishes starting you should be able to add it to your flow.</p>

<p>Nifi.rocks will follow up with how to generate unit tests and documentation for your custom processors soon.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Nifi: What Processors are there?]]></title>
    <link href="http://www.nifi.rocks/apache-nifi-processors/"/>
    <updated>2015-02-05T03:00:06+00:00</updated>
    <id>http://www.nifi.rocks/apache-nifi-processors</id>
    <content type="html"><![CDATA[<p><strong> Includes all processors through release 0.0.2 </strong></p>

<p>I looked around at what can be done with Apache NiFi and didn&rsquo;t notice a list of processors without looking at the code or building the project.  I think a list of available processors, the work horse of Apache Nifi, would greatly help decide if it is right for certain needs.  So, I went into the usage guide in the Apache Nifi UI and pulled a list of processors and a quick description for those who want to know what possibilities there are before getting into nifi itself!</p>

<h1>List of processors</h1>

<p>Here is a list of all 53 processors, listed alphabetically, that are currently in Apache Nifi as of February 5th, 2015.  Each one links to a description of the processor further down.  The Usage documentation available in the web ui has much more detail about each processor, it&rsquo;s properties, modifiable attributes, and relationships and each processor has it&rsquo;s own page in the UI, so here is just a quick overview.  Again, this content is taken directly from Nifi&rsquo;s Usage guide in their web UI and all credit/rights belong to them under the Apache 2.0 License.</p>

<!--more -->


<ul>
<li><a href="#Base64EncodeContent">Base64EncodeContent</a></li>
<li><a href="#CompressContent">CompressContent</a></li>
<li><a href="#ControlRate">ControlRate</a></li>
<li><a href="#ConvertCharacterSet">ConvertCharacterSet</a></li>
<li><a href="#ConvertCSVToAvro">ConvertCSVToAvro</a></li>
<li><a href="#ConvertJSONToAvro">ConvertJSONToAvro</a></li>
<li><a href="#CreateHadoopSequenceFile">CreateHadoopSequenceFile</a></li>
<li><a href="#DetectDuplicate">DetectDuplicate</a></li>
<li><a href="#DistributeLoad">DistributeLoad</a></li>
<li><a href="#EncryptContent">EncryptContent</a></li>
<li><a href="#EvaluateJSONPath">EvaluateJSONPath</a></li>
<li><a href="#EvaluateRegularExpression">EvaluateRegularExpression</a></li>
<li><a href="#EvaluateXPath">EvaluateXPath</a></li>
<li><a href="#EvaluateXQuery">EvaluateXQuery</a></li>
<li><a href="#ExecuteProcess">ExecuteProcess</a></li>
<li><a href="#ExecuteStreamCommand">ExecuteStreamCommand</a></li>
<li><a href="#GenerateFlowFile">GenerateFlowFile</a></li>
<li><a href="#GetFile">GetFile</a></li>
<li><a href="#GetFTP">GetFTP</a></li>
<li><a href="#GetHDFS">GetHDFS</a></li>
<li><a href="#GetHDFSSequenceFile">GetHDFSSequenceFile</a></li>
<li><a href="#GetHTTP">GetHTTP</a></li>
<li><a href="#GetJMSQueue">GetJMSQueue</a></li>
<li><a href="#GetJMSTopic">GetJMSTopic</a></li>
<li><a href="#GetKafka">GetKafka</a></li>
<li><a href="#GetSFTP">GetSFTP</a></li>
<li><a href="#HandleHttpRequest">HandleHttpRequest</a></li>
<li><a href="#HandleHttpResponse">HandleHttpResponse</a></li>
<li><a href="#HashAttribute">HashAttribute</a></li>
<li><a href="#HashContent">HashContent</a></li>
<li><a href="#IdentifyMimeType">IdentifyMimeType</a></li>
<li><a href="#InvokeHTTP">InvokeHTTP</a></li>
<li><a href="#ListenHTTP">ListenHTTP</a></li>
<li><a href="#ListenUDP">ListenUDP</a></li>
<li><a href="#LogAttribute">LogAttribute</a></li>
<li><a href="#MergeContent">MergeContent</a></li>
<li><a href="#ModifyBytes">ModifyBytes</a></li>
<li><a href="#MonitorActivity">MonitorActivity</a></li>
<li><a href="#PostHTTP">PostHTTP</a></li>
<li><a href="#PutEmail">PutEmail</a></li>
<li><a href="#PutFile">PutFile</a></li>
<li><a href="#PutFTP">PutFTP</a></li>
<li><a href="#PutHDFS">PutHDFS</a></li>
<li><a href="#PutJMS">PutJMS</a></li>
<li><a href="#PutKafka">PutKafka</a></li>
<li><a href="#PutSFTP">PutSFTP</a></li>
<li><a href="#ReplaceText">ReplaceText</a></li>
<li><a href="#ReplaceTextWithMapping">ReplaceTextWithMapping</a></li>
<li><a href="#RouteOnAttribute">RouteOnAttribute</a></li>
<li><a href="#RouteOnContent">RouteOnContent</a></li>
<li><a href="#ScanAttribute">ScanAttribute</a></li>
<li><a href="#ScanContent">ScanContent</a></li>
<li><a href="#SegmentContent">SegmentContent</a></li>
<li><a href="#SplitContent">SplitContent</a></li>
<li><a href="#SplitJson">SplitJson</a></li>
<li><a href="#SplitText">SplitText</a></li>
<li><a href="#SplitXML">SplitXML</a></li>
<li><a href="#StoreInKiteDataset">StoreInKiteDataset</a></li>
<li><a href="#TransformXML">TransformXML</a></li>
<li><a href="#UnpackContent">UnpackContent</a></li>
<li><a href="#UpdateAttribute">UpdateAttribute</a></li>
<li><a href="#ValidateXML">ValidateXML</a></li>
</ul>


<h3><a name="Base64EncodeContent"></a>Base64EncodeContent</h3>

<p>This processor base64 encodes FlowFile content, or decodes FlowFile content from base64.</p>

<h3><a name="CompressContent"></a>CompressContent</h3>

<p>This processor compresses and decompresses the contents of FlowFiles using a user-specified compression algorithm.</p>

<h3><a name="ControlRate"></a>ControlRate</h3>

<p>This processor controls the rate at which data is transferred to follow-on processors.</p>

<h3><a name="ConvertCharacterSet"></a>ConvertCharacterSet</h3>

<p>This processor converts a FlowFile&rsquo;s content from one character set to another.</p>

<h3><a name="ConvertCSVToAvro"></a>ConvertCSVToAvro</h3>

<p>No description is given for this processor.</p>

<h3><a name="ConvertJSONToAvro"></a>ConvertJSONToAvro</h3>

<p>No description is given for this processor.</p>

<h3><a name="CreateHadoopSequenceFile"></a>CreateHadoopSequenceFile</h3>

<p>This processor is used to create a Hadoop Sequence File, which essentially is a file of key/value pairs. The key will be a file name and the value will be the flow file content. The processor will take either a merged (a.k.a. packaged) flow file or a singular flow file. Historically, this processor handled the merging by type and size or time prior to creating a SequenceFile output; it no longer does this. If creating a SequenceFile that contains multiple files of the same type is desired, precede this processor with a RouteOnAttribute processor to segregate files of the same type and follow that with a MergeContent processor to bundle up files. If the type of files is not important, just use the MergeContent processor. When using the MergeContent processor, the following Merge Formats are supported by this processor:</p>

<p>TAR
ZIP
FlowFileStream v3
The created SequenceFile is named the same as the incoming FlowFile with the suffix &lsquo;.sf&rsquo;. For incoming FlowFiles that are bundled, the keys in the SequenceFile are the individual file names, the values are the contents of each file.
NOTE: The value portion of a key/value pair is loaded into memory. While there is a max size limit of 2GB, this could cause memory issues if there are too many concurrent tasks and the flow file sizes are large.</p>

<h3><a name="DetectDuplicate"></a>DetectDuplicate</h3>

<p>This processor detects duplicate data by examining flow file attributes, thus allowing the user to configure what it means for two FlowFiles to be considered &ldquo;duplicates&rdquo;. This processor does not read the contents of a flow file, and is typically preceded by another processor which computes a value based on the flow file content and adds that value to the flow file&rsquo;s attributes; e.g. HashContent. Because this Processor needs to be able to work within a NiFi cluster, it makes use of a distributed cache service to determine whether or not the data has been seen previously.</p>

<p>If the processor is to be run on a standalone instance of NiFi, that instance should have both a DistributedMapCacheClient and a DistributedMapCacheServer configured in its controller-services.xml file.</p>

<h3><a name="DistributeLoad"></a>DistributeLoad</h3>

<p>This processor distributes FlowFiles to downstream processors based on a distribution strategy. The user may select the strategy &ldquo;round robin&rdquo;, the strategy &ldquo;next available&rdquo;, or &ldquo;load distribution service&rdquo;. If using the round robin strategy, the default is to assign each destination (i.e., relationship) a weighting of 1 (evenly distributed). However, the user may add optional properties to change this weighting. When adding a property, the name must be a positive integer between 1 and the number of relationships (inclusive). For example, if Number of Relationships has a value of 8 and a property is added with the name 5 and the value 10, then relationship 5 (among the 8) will receive 10 FlowFiles in each iteration instead of 1. All other relationships will receive 1 FlowFile in each iteration.</p>

<h3><a name="EncryptContent"></a>EncryptContent</h3>

<p>This processor encrypts or decrypts FlowFiles.</p>

<h3><a name="EvaluateJsonPath"></a>EvaluateJsonPath</h3>

<p>Evaluates one or more JsonPath expressions against the content of a FlowFile. The results of those expressions are assigned to FlowFile Attributes or are written to the content of the FlowFile itself, depending on configuration of the Processor. JsonPaths are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed (if the Destination is flowfile-attribute; otherwise, the property name is ignored). The value of the property must be a valid JsonPath expression. If the JsonPath evaluates to a JSON array or JSON object and the Return Type is set to &lsquo;scalar&rsquo; the FlowFile will be unmodified and will be routed to failure. A Return Type of JSON can return scalar values if the provided JsonPath evaluates to the specified value and will be routed as a match. If Destination is &lsquo;flowfile-content&rsquo; and the JsonPath does not evaluate to a defined path, the FlowFile will be routed to &lsquo;unmatched&rsquo; without having its contents modified. If Destination is flowfile-attribute and the expression matches nothing, attributes will be created with empty strings as the value, and the FlowFile will always be routed to &lsquo;matched&rsquo;.</p>

<h3><a name="EvaluateRegularExpression"></a>EvaluateRegularExpression</h3>

<p>This processor evaluates one or more Regular Expressions against the content of a FlowFile. The results of those Regular Expressions are assigned to FlowFile Attributes. Regular Expressions are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed. The value of the property must be a valid Regular Expressions with exactly one capturing group. If the Regular Expression matches more than once, only the first match will be used. If any provided Regular Expression matches, the FlowFile(s) will be routed to &lsquo;matched&rsquo;. If no provided Regular Expression matches, the FlowFile will be routed to &lsquo;unmatched&rsquo; and no attributes will be applied to the FlowFile.</p>

<h3><a name="EvaluateXPath"></a>EvaluateXPath</h3>

<p>This processor evaluates one or more XPaths against the content of FlowFiles. The results of those XPaths are assigned to FlowFile attributes or are written to the content of the FlowFile itself, depending on how the user configures the Destination and Return Type properties in the processor. XPaths are entered by adding user-defined properties; the name of each user-added property maps to the attribute name into which the result should be placed. The value of the property must be a valid XPath expression.</p>

<h3><a name="EvaluateXQuery"></a>EvaluateXQuery</h3>

<p>This processor evaluates one or more XQueries against the content of FlowFiles. The results of those XQueries are assigned to FlowFile attributes or are written to the content of the FlowFile itself, depending on how the user configures the Destination property in the processor. One attribute or FlowFile is produced for each XQuery result. Each produced FlowFile will carry the attributes of the input FlowFile. See the &ldquo;Examples&rdquo; section for details on how multiple results can be wrapped or concatenated. XQueries are entered by adding user-defined properties; the name of each user-added property maps to the attribute name into which the result should be placed. The value of the property must be a valid XQuery expression.</p>

<h3><a name="ExecuteProcess"></a>ExecuteProcess</h3>

<p>Runs an operating system command specified by the user and writes the output of that command to a FlowFile. If the command is expected to be long-running, the Processor can output the partial data on a specified interval. When this option is used, the output is expected to be in textual format, as it typically does not make sense to split binary data on arbitrary time-based intervals.</p>

<h3><a name="ExecuteStreamCommand"></a>ExecuteStreamCommand</h3>

<p>This processor executes an external command on the contents of a FlowFile, and creates a new FlowFile with the results of the command.</p>

<h3><a name="GenerateFlowFile"></a>GenerateFlowFile</h3>

<p>This processor creates FlowFiles of random data to be used for load testing purposes.</p>

<h3><a name="GetFile"></a>GetFile</h3>

<p>This processor obtains FlowFiles from a local directory. NiFi will need at least read permissions on the files it will pull otherwise it will ignore them.</p>

<h3><a name="GetFTP"></a>GetFTP</h3>

<p>This processor fetches files from an FTP server and creates FlowFiles from them.</p>

<h3><a name="GetHDFS"></a>GetHDFS</h3>

<p>This processor reads files from an HDFS cluster into NiFi FlowFiles.</p>

<h3><a name="GetHDFSSequenceFile"></a>GetHDFSSequenceFile</h3>

<p>This processor is used to pull files from HDFS. The files being pulled in MUST be SequenceFile formatted files. The processor creates a flow file for each key/value entry in the ingested SequenceFile. The created flow file&rsquo;s content depends on the value of the optional configuration property FlowFile Content. Currently, there are two choices: VALUE ONLY and KEY VALUE PAIR. With the prior, only the SequenceFile value element is written to the flow file contents. With the latter, the SequenceFile key and value are written to the flow file contents as serialized objects; the format is key length (int), key(String), value length(int), value(bytes). The default is VALUE ONLY.</p>

<p>NOTE: This processor loads the entire value entry into memory. While the size limit for a value entry is 2GB, this will cause memory problems if there are too many concurrent tasks and the data being ingested is large.</p>

<h3><a name="GetHTTP"></a>GetHTTP</h3>

<p>This processor fetches files via HTTP and creates FlowFiles from them.</p>

<h3><a name="GetJMSQueue"></a>GetJMSQueue</h3>

<p>This processor pulls messages from a JMS Queue, creating a FlowFile for each JMS message or bundle of messages, as configured.</p>

<h3><a name="GetJMSTopic"></a>GetJMSTopic</h3>

<p>This processor pulls messages from a JMS Topic, creating a FlowFile for each JMS message or bundle of messages, as configured.</p>

<h3><a name="GetKafka"></a>GetKafka</h3>

<p>This Processors polls Apache Kafka for data. When a message is received from Kafka, this Processor emits a FlowFile where the content of the FlowFile is the value of the Kafka message. If the message has a key associated with it, an attribute named kafka.key will be added to the FlowFile, with the value being the UTF-8 Encoded value of the Message&rsquo;s Key.</p>

<p>Kafka supports the notion of a Consumer Group when pulling messages in order to provide scalability while still offering a publish-subscribe interface. Each Consumer Group must have a unique identifier. The Consumer Group identifier that is used by NiFi is the UUID of the Processor. This means that all of the nodes within a cluster will use the same Consumer Group Identifier so that they do not receive duplicate data but multiple GetKafka Processors can be used to pull from multiple Topics, as each Processor will receive a different Processor UUID and therefore a different Consumer Group Identifier.</p>

<h3><a name="GetSFTP"></a>GetSFTP</h3>

<p>This processor pulls files from an SFTP server and creates FlowFiles to encapsulate them.</p>

<h3><a name="HandleHttpRequest"></a>HandleHttpRequest</h3>

<p>This processor starts an HTTP server and creates a FlowFile for each HTTP Request that it receives. The Processor leaves the HTTP Connection open and is intended to be used in conjunction with a HandleHttpResponse Processor.</p>

<p>The pairing of this Processor with a HandleHttpResponse Processor provides the ability to use NiFi to visually construct a web server that can carry out any functionality that is available through the existing Processors. For example, one could construct a Web-based front end to an SFTP Server by constructing a flow such as:</p>

<p>HandleHttpRequest -> PutSFTP -> HandleHttpResponse</p>

<p>The HandleHttpRequest Processor provides several Properties to configure which methods are supported, the paths that are supported, and SSL configuration. The FlowFiles that are generated by this Processor have the following attributes added to them, providing powerful routing capabilities and traceability of all data.</p>

<h3><a name="HandleHttpResponse"></a>HandleHttpResponse</h3>

<p>This processor responds to an HTTP request that was received by the HandleHttpRequest Processor.</p>

<p>The pairing of this Processor with a HandleHttpRequest Processor provides the ability to use NiFi to visually construct a web server that can carry out any functionality that is available through the existing Processors. For example, one could construct a Web-based front end to an SFTP Server by constructing a flow such as:</p>

<p>HandleHttpRequest -> PutSFTP -> HandleHttpResponse</p>

<p>This Processor must be configured with the same <HTTP Context Map> service as the corresponding HandleHttpRequest Processor. Otherwise, all FlowFiles will be routed to the &lsquo;failure&rsquo; relationship.</p>

<p>All FlowFiles must have an attribute named http.context.identifier. The value of this attribute is used to lookup the HTTP Response so that the proper message can be sent back to the requestor. If this attribute is missing, the FlowFile will be routed to &lsquo;failure.&rsquo;</p>

<h3><a name="HashAttribute"></a>HashAttribute</h3>

<p>This processor hashes together the key/value pairs of several FlowFile attributes and adds the hash as a new attribute. The user may add optional properties such that the name of each property is the name of a FlowFile attribute to consider and the value of the property is a regular expression that, if matched by the attribute value, causes that attribute to be used as part of the hash. If the regular expression contains a capturing group, only the value of the capturing group is used.</p>

<h3><a name="HashContent"></a>HashContent</h3>

<p>This processor calculates a hash value for the content of a FlowFile and puts the hash value on the FlowFile as an attribute whose name is determined by the Hash Attribute Name property.</p>

<h3><a name="IdentifyMimeType"></a>IdentifyMimeType</h3>

<p>This processor attempts to identify the MIME type used for a FlowFile. If the MIME type can be identified, an attribute with the name mime.type is added to the FlowFile, and its value is the detected MIME type. Some MIME types require the processor to read a significant amount of data; for these MIME types, their identification is optional. (See the properties Identify ZIP and Identify TAR.) The algorithm may have to read the entire contents of a file for each type of identification. If the MIME Type cannot be determined, its mime.type attribute will be set to application/octet-stream .</p>

<p>The following MIME Types are detected:</p>

<ul>
<li>application/gzip</li>
<li>application/bzip2</li>
<li>application/flowfile-v3</li>
<li>application/flowfile-v1 (requires Identify TAR be set to true)</li>
<li>application/xml</li>
<li>video/mp4</li>
<li>video/x-m4v</li>
<li>video/mp4a-latm</li>
<li>video/quicktime</li>
<li>video/mpeg</li>
<li>audio/wav</li>
<li>audio/mp3</li>
<li>image/bmp</li>
<li>image/png</li>
<li>image/jpg</li>
<li>image/gif</li>
<li>image/tif</li>
<li>application/vnd.ms-works</li>
<li>application/msexcel</li>
<li>application/mspowerpoint</li>
<li>application/msaccess</li>
<li>application/x-ms-wmv</li>
<li>application/pdf</li>
<li>application/x-rpm</li>
<li>application/tar</li>
<li>application/x-7z-compressed</li>
<li>application/java-archive</li>
<li>application/zip</li>
<li>application/x-lzh</li>
</ul>


<h3><a name="InvokeHTTP"></a>InvokeHTTP</h3>

<p>Making requests to remote HTTP servers. Supporting common HTTP methods. Storing results as new flowfiles upon success. Routing to failure on error.</p>

<p>An HTTP client processor that converts FlowFile attributes to HTTP headers with configurable HTTP method, URL, etc.</p>

<h3><a name="ListenHTTP"></a>ListenHTTP</h3>

<p>This processor starts an HTTP service that is used to receive FlowFiles from remote sources. The URL of the service is <a href="http://">http://</a>{hostname}:{port}/contentListener.</p>

<h3><a name="ListenUDP"></a>ListenUDP</h3>

<p>This processor listens for Datagram Packets on a given port and concatenates the contents of those packets together generating FlowFiles roughly as often as the internal buffer fills up or until no more data is currently available.</p>

<h3><a name="LogAttribute"></a>LogAttribute</h3>

<p>This processor reads the attributes on incoming FlowFiles and prints those attributes and their values to the log at the logging level specified by the user.</p>

<h3><a name="MergeContent"></a>MergeContent</h3>

<p>This processor merges a group of FlowFiles together into a &ldquo;Bundle&rdquo; based on a user-defined strategy and packages them into a single FlowFile. It is recommended that the processor be configured with only a single incoming connection, as groups of FlowFiles will not be created from FlowFiles in different connections. This processor updates the mime.type attribute as appropriate. After files have been merged by this processor, they can be unpackaged later using the UnpackContent processor.</p>

<h3><a name="ModifyBytes"></a>ModifyBytes</h3>

<p>This processor updates the content of a FlowFile by removing bytes from start or end of a file.</p>

<h3><a name="MonitorActivity"></a>MonitorActivity</h3>

<p>This processor monitors its point in the dataflow for activity and sends a notice when there is a lack of data flowing through it for some user-specified amount of time; it then sends another notice when the flow of data resumes.</p>

<h3><a name="PostHTTP"></a>PostHTTP</h3>

<p>This processor performs an HTTP post with the content of each incoming FlowFile.</p>

<h3><a name="PutEmail"></a>PutEmail</h3>

<p>This processor sends an e-mail to configured recipients for each incoming FlowFile.</p>

<h3><a name="PutFile"></a>PutFile</h3>

<p>This processor writes FlowFiles to the local file system.</p>

<h3><a name="PutFTP"></a>PutFTP</h3>

<p>This processor sends FlowFiles via FTP to an FTP server.</p>

<h3><a name="PutHDFS"></a>PutHDFS</h3>

<p>This processor writes FlowFiles to an HDFS cluster. It will create directories in which to store files as needed based on the Directory property.</p>

<p>When files are written to HDFS, the file&rsquo;s owner is the user identity of the NiFi process, the file&rsquo;s group is the group of the parent directory, and the read/write/execute permissions use the default umask. The owner can be overridden using the Remote Owner property, the group can be overridden using the Remote Group property, and the read/write/execute permissions can be overridden using the Permissions umask property.</p>

<p>NOTE: This processor can change owner or group only if the user identity of the NiFi process has super user privilege in HDFS to do so.</p>

<p>NOTE: The Permissions umask property cannot add execute permissions to regular files.</p>

<h3><a name="PutJMS"></a>PutJMS</h3>

<p>This processor creates a JMS message from the contents of a FlowFile and sends the message to a JMS server.</p>

<h3><a name="PutKafka"></a>PutKafka</h3>

<p>This Processors puts the contents of a FlowFile to a Topic in Apache Kafka. The full contents of a FlowFile becomes the contents of a single message in Kafka. This message is optionally assigned a key by using the <Kafka Key> Property.</p>

<p>The Processor allows the user to configure an optional Message Delimiter that can be used to send many messages per FlowFile. For example, a \n could be used to indicate that the contents of the FlowFile should be used to send one message per line of text. If the property is not set, the entire contents of the FlowFile will be sent as a single message. When using the delimiter, if some messages are successfully sent but other messages fail to send, the FlowFile will be FORKed into two child FlowFiles, with the successfully sent messages being routed to &lsquo;success&rsquo; and the messages that could not be sent going to &lsquo;failure&rsquo;.</p>

<h3><a name="PutSFTP"></a>PutSFTP</h3>

<p>This processor sends FlowFiles via SFTP to an SFTP server.</p>

<h3><a name="ReplaceText"></a>ReplaceText</h3>

<p>This processor updates the content of a FlowFile by evaluating a regular expression (regex) against the content and replacing the section of content that matches the regular expression with an alternate, user-defined, value.</p>

<h3><a name="ReplaceTextWithMapping"></a>ReplaceTextWithMapping</h3>

<p>This processor updates the content of a FlowFile by evaluating a regular expression (regex) against the content and replacing the section of content that matches a specified matching  group of the regular expression with an alternate, user-defined, value provided in a mapping file.  The mapping file is formatted as one key/value pair per line, seperated by tabs.</p>

<h3><a name="RouteOnAttribute"></a>RouteOnAttribute</h3>

<p>This processor routes FlowFiles based on their attributes using the NiFi Expression Language. Users add properties with valid NiFi Expression Language Expressions as the values. Each Expression must return a value of type Boolean (true or false).</p>

<p>Example: The goal is to route all files with filenames that start with ABC down a certain path. Add a property with the following name and value:</p>

<p>property name: ABC
property value: ${filename:startsWith(&lsquo;ABC&rsquo;)}
In this example, all files with filenames that start with ABC will follow the ABC relationship.</p>

<h3><a name="RouteOnContent"></a>RouteOnContent</h3>

<p>This processor applies user-added regular expressions to the content of a FlowFile and routes a copy of the FlowFile to each destination whose regular expression matches. The user adds properties where the name is the relationship that the FlowFile should follow if it matches the regular expression, which is defined as the property&rsquo;s value. User-defined properties do support the NiFi Expression Language, but in such cases, the results are interpreted as literal values, not regular expressions.</p>

<h3><a name="ScanAttribute"></a>ScanAttribute</h3>

<p>This processor scans the specified attributes of FlowFiles, checking to see if any of their values are present within the specified dictionary of terms.</p>

<h3><a name="ScanContent"></a>ScanContent</h3>

<p>This processor scans the content of FlowFiles for terms that are found in a user-supplied dictionary file. If a term is matched, the UTF-8 encoded version of the term is added to the FlowFile using the matching.term attribute. This allows for follow-on processors to use the value of the matching.term attribute to make routing decisions and so forth.</p>

<h3><a name="SegmentContent"></a>SegmentContent</h3>

<p>This processor segments a FlowFile into multiple smaller segments on byte boundaries. Each segment is given attributes that can then be used by the MergeContent processor to reconstruct the original FlowFile.</p>

<h3><a name="SplitContent"></a>SplitContent</h3>

<p>This processor splits incoming FlowFiles by a specified byte sequence.</p>

<h3><a name="SplitJson"></a>SplitJson</h3>

<p>This processor splits a JSON File into multiple, separate FlowFiles for an array element specified by a JsonPath expression. Each generated FlowFile is comprised of an element of the specified array and transferred to relationship &lsquo;split,&rsquo; with the original file transferred to the &lsquo;original&rsquo; relationship. If the specified JsonPath is not found or does not evaluate to an array element, the original file is routed to &lsquo;failure&rsquo; and no files are generated.</p>

<p>Note: The underlying JsonPath library loads the entirety of the streamed content into and performs result evaluations in memory. Accordingly, it is important to consider the anticipated profile of content being evaluated by this processor and the hardware supporting it especially when working against large JSON documents.</p>

<h3><a name="SplitText"></a>SplitText</h3>

<p>This processor splits a text file into multiple smaller text files on line boundaries, each having up to a configured number of lines.</p>

<h3><a name="SplitXML"></a>SplitXML</h3>

<p>This processor splits an XML file into multiple separate FlowFiles, each comprising a child or descendant of the original root element.</p>

<h3><a name="StoreInKiteDataset"></a>StoreInKiteDataset</h3>

<p>No description is given for this processor.</p>

<h3><a name="TransformXML"></a>TransformXML</h3>

<p>This processor transforms the contents of FlowFiles based on a user-specified XSLT stylesheet file. XSL versions 1.0 and 2.0 are supported.</p>

<h3><a name="UnpackContent"></a>UnpackContent</h3>

<p>This processor unpacks the content of FlowFiles that have been packaged with one of several different packaging formats, emitting one to many FlowFiles for each input FlowFile.</p>

<h3><a name="UpdateAttribute"></a>UpdateAttribute</h3>

<p>This processor updates the attributes of a FlowFile using properties or rules that are added by the user. There are two ways to use this processor to add or modify attributes. One way is the &ldquo;Basic Usage&rdquo;; this allows you to set default attribute changes that affect every FlowFile going through the processor. The second way is the &ldquo;Advanced Usage&rdquo;; this allows you to make conditional attribute changes that only affect a FlowFile if it meets certain conditions. It is possible to use both methods in the same processor at the same time.</p>

<h3><a name="ValidateXML"></a>ValidateXML</h3>

<p>This processor validates the contents of FlowFiles against a user-specified XML schema file.</p>

<p>If you have questions about a processor, I&rsquo;d encourage you to download the binaries and start up Apache Nifi.  If you really want more information, let me know and I&rsquo;ll try to compile a more complete post about each and every processor.</p>
]]></content>
  </entry>
  
</feed>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 -   <br/>
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> + <a href="https://github.com/ioveracker/mnml">mnml</a>.
	  
  </span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'nifirocks';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
